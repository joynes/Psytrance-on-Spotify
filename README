#------------------------------------------------------
#What are the steps?
#------------------------------------------------------
echo -------------------------------------------
echo Download all the search pages
echo -------------------------------------------

year=${1:?"Usage: echo $0 <year>"}
exit 1
cd pages
mkdir $year
cd $year
exit 1
i=1; while [ $i -lt 44 ]; do nr=$i; [ $nr -lt 10 ] && nr=0$nr; [ -e $i.html ] || { curl -d "boolean=AND&case=INSENSITIVE&cd=TRUE&dw=TRUE&cs=TRUE&vinyl=TRUE&dvd=TRUE&terms=$year%2F$nr" http://www.psyshop.com/cgi-bin/search.cgi > $i.html; }; let i=i+1; done

echo -------------------------------------------
echo Get all individual links from theese pages
echo -------------------------------------------

grep '<TD ALIGN=.*><TABLE><TR><TD ALIGN=.*><A HREF="http://www.psyshop.com' *.html | sed 's/.*"\(ht.*html\)">.*/\1/' > links.txt
echo "Found " `cat links.txt | wc | awk '{print $1}'` albums
mkdir albums
cd albums

echo -------------------------------------------
echo Get all individual pages.. will take time..
echo -------------------------------------------

i=0; cat ../links.txt |  while read in; do [ -e $i.html ] || { curl $in > $i.html; echo $in > $i.link; }; let i=$i+1; done


echo -------------------------------------------
echo  Parse all the pages and get the inserts
echo -------------------------------------------

size=`ls | sort -n | grep "\.link$" | tail -n 1 | sed 's/.link//'`
i=0; while [ $i -lt $size ]; do python ../../../parser.py  $i.html `cat $i.link`; let i=i+1; done  | tee inserts.txt

rm data.php
echo '<?php $array = array(' >> data.php
cat inserts.txt | grep "^array(" >> data.php
echo '); ?>' >> data.php

. ../../../passwords/ftp_uri.sh
ftp "$ftp_uri" <<EOF
put data.php psytrance.se/data.php
EOF

curl "http://psytrance.se/export.php" | tee result.log

echo "inserted " `cat result.log | grep "Sucess insert" | wc | awk '{print $1}'` " albums"

#------------------------------------------------------
#------------------------------------------------------
